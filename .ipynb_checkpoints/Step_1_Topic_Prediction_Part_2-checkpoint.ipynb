{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>category</th>\n",
       "      <th>combined</th>\n",
       "      <th>content_size</th>\n",
       "      <th>title_size</th>\n",
       "      <th>tags_size</th>\n",
       "      <th>TitleNTags</th>\n",
       "      <th>ContentNTags</th>\n",
       "      <th>title_pred</th>\n",
       "      <th>content_pred</th>\n",
       "      <th>combined_pred</th>\n",
       "      <th>title_nouns</th>\n",
       "      <th>content_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>criticality ribosome binding site relative sta...</td>\n",
       "      <td>prokaryotic translation critical efficient tra...</td>\n",
       "      <td>['ribosome', 'binding-sites', 'translation', '...</td>\n",
       "      <td>biology</td>\n",
       "      <td>criticality ribosome binding site relative sta...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>criticality ribosome prokaryotic codon</td>\n",
       "      <td>translation 7b observable prokaryotic</td>\n",
       "      <td>translation prokaryotic ribosome codon</td>\n",
       "      <td>criticality ribosome binding site relative sta...</td>\n",
       "      <td>prokaryotic translation critical efficient tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>rnase contamination rna based experiments prev...</td>\n",
       "      <td>anyone suggestions prevent rnase contamination...</td>\n",
       "      <td>['rna', 'biochemistry']</td>\n",
       "      <td>biology</td>\n",
       "      <td>rnase contamination rna based experiments prev...</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>prevented rnase contamination experiments</td>\n",
       "      <td>rnase depc pipette degradation</td>\n",
       "      <td>rnase contamination rna depc</td>\n",
       "      <td>rnase contamination rna based experiment preve...</td>\n",
       "      <td>doe anyone suggestion prevent rnase contaminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>lymphocyte sizes clustered two groups</td>\n",
       "      <td>tortora writes principles anatomy physiology l...</td>\n",
       "      <td>['immunology', 'cell-biology', 'hematology']</td>\n",
       "      <td>biology</td>\n",
       "      <td>lymphocyte sizes clustered two groups tortora ...</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>clustered lymphocyte groups sizes</td>\n",
       "      <td>lymphocytes diameter tortora 14</td>\n",
       "      <td>lymphocytes clustered groups sizes</td>\n",
       "      <td>lymphocyte size clustered group</td>\n",
       "      <td>tortora principle anatomy physiology lymphocyt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1  id  \\\n",
       "0           0             0             0   1   \n",
       "1           1             1             1   2   \n",
       "2           2             2             2   3   \n",
       "\n",
       "                                               title  \\\n",
       "0  criticality ribosome binding site relative sta...   \n",
       "1  rnase contamination rna based experiments prev...   \n",
       "2              lymphocyte sizes clustered two groups   \n",
       "\n",
       "                                             content  \\\n",
       "0  prokaryotic translation critical efficient tra...   \n",
       "1  anyone suggestions prevent rnase contamination...   \n",
       "2  tortora writes principles anatomy physiology l...   \n",
       "\n",
       "                                                tags category  \\\n",
       "0  ['ribosome', 'binding-sites', 'translation', '...  biology   \n",
       "1                            ['rna', 'biochemistry']  biology   \n",
       "2       ['immunology', 'cell-biology', 'hematology']  biology   \n",
       "\n",
       "                                            combined  content_size  \\\n",
       "0  criticality ribosome binding site relative sta...            24   \n",
       "1  rnase contamination rna based experiments prev...            21   \n",
       "2  lymphocyte sizes clustered two groups tortora ...            31   \n",
       "\n",
       "   title_size  tags_size  TitleNTags  ContentNTags  \\\n",
       "0           9          4           2             2   \n",
       "1           6          2           1             1   \n",
       "2           5          3           0             0   \n",
       "\n",
       "                                  title_pred  \\\n",
       "0     criticality ribosome prokaryotic codon   \n",
       "1  prevented rnase contamination experiments   \n",
       "2          clustered lymphocyte groups sizes   \n",
       "\n",
       "                            content_pred  \\\n",
       "0  translation 7b observable prokaryotic   \n",
       "1         rnase depc pipette degradation   \n",
       "2        lymphocytes diameter tortora 14   \n",
       "\n",
       "                            combined_pred  \\\n",
       "0  translation prokaryotic ribosome codon   \n",
       "1            rnase contamination rna depc   \n",
       "2      lymphocytes clustered groups sizes   \n",
       "\n",
       "                                         title_nouns  \\\n",
       "0  criticality ribosome binding site relative sta...   \n",
       "1  rnase contamination rna based experiment preve...   \n",
       "2                    lymphocyte size clustered group   \n",
       "\n",
       "                                       content_nouns  \n",
       "0  prokaryotic translation critical efficient tra...  \n",
       "1  doe anyone suggestion prevent rnase contaminat...  \n",
       "2  tortora principle anatomy physiology lymphocyt...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob \n",
    "\n",
    "os.chdir('/Users/daniellee/Desktop/Kaggle/data/stackoverflow_data/')\n",
    "\n",
    "train = pd.read_csv('cleaned/topic_model_df_train.csv'); train.head(3)\n",
    "test = pd.read_csv('cleaned/topic_model_df_test.csv'); train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Partitions of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "partitions = train_test_split(train.drop('category',axis=1), train['category'])\n",
    "\n",
    "os.chdir('/Users/daniellee/Desktop/Kaggle/data/stackoverflow_data/experiment_test_set/')\n",
    "for name, part in zip(['trainX', 'testX', 'trainy', 'testy'], partitions):\n",
    "    part.to_csv(name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainy, testy = [df.reset_index() for df in partitions] \n",
    "trainX = trainX.ix[:,5:]\n",
    "testX = testX.ix[:,5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Text Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove blanks\n",
    "trainX['content'] = trainX['content'].fillna('')\n",
    "testX['content'] = testX['content'].fillna('')\n",
    "\n",
    "trainBlankLoc = trainX['content'] == ''\n",
    "testBlankLoc = testX['content'] == ''\n",
    " \n",
    "trainX.ix[trainBlankLoc, 'combined'] = trainX.ix[trainBlankLoc, 'title'] + trainX.ix[trainBlankLoc, 'content']\n",
    "testX.ix[testBlankLoc, 'combined'] = testX.ix[testBlankLoc, 'title'] + testX.ix[testBlankLoc, 'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX['stemmed'] = ''\n",
    "testX['stemmed'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snow = SnowballStemmer('english')\n",
    "def stemmer(x):\n",
    "    return ' '.join([snow.stem(word) for word in x.split()]) \n",
    "\n",
    "trainX['combined'] = trainX['combined'].map(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_digit(text):\n",
    "    try:\n",
    "        float(text)\n",
    "        return True \n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def numeric_replacer(x):\n",
    "    new_set = []\n",
    "    for word in x.split():\n",
    "        if is_digit(word):\n",
    "            new_set.append('digitstring')\n",
    "        else:\n",
    "            new_set.append(word)\n",
    "    \n",
    "    return ' '.join(new_set)\n",
    "\n",
    "trainX['combined'] = trainX['combined'].map(numeric_replacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GetBowDummies(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs: (1) Series with a text vector (2) Bag of Words for features\n",
    "    Output: Dataframe with dummy variables indicating whether a feature word is present in a row.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    train = pd.Series(['I dont know','polish dont','fire','healthcare know','healthcare'])\n",
    "    test  = pd.Series(['I dont know','healthcare know'])\n",
    "    feats = ['dont','know','healthcare']\n",
    "\n",
    "    train_bow_dummies = GetBowDummies(train, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies = GetBowDummies(test, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies\n",
    "     >> dont  know  healthcare\n",
    "        0     0     0           0\n",
    "        1     0     0           0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    def __init__(self, series, features):\n",
    "        \"\"\"\n",
    "        :param series: A column containing raw text\n",
    "        :param features: A list of feature words\n",
    "        \"\"\"\n",
    "        self.series = series\n",
    "        self.index  = self.series.index\n",
    "        self.features = features\n",
    "\n",
    "        # Define dimension\n",
    "        self.nrows = series.shape[0]\n",
    "        self.ncols = len(features)\n",
    "        self.dim   = (self.nrows, self.ncols)\n",
    "\n",
    "    def index_feats_dict(self):\n",
    "        \"\"\"\n",
    "        For every document row, features present in doc\n",
    "        identified.\n",
    "        \"\"\"\n",
    "        doc_features_dict = {}\n",
    "\n",
    "        for index, doc in zip(self.index, self.series):\n",
    "            # Sets for a doc and feature words\n",
    "            \n",
    "            doc_set = set(doc.split())\n",
    "            feat_set = set(self.features)\n",
    "\n",
    "            # Shared words between the two sets\n",
    "            interset_words = doc_set.intersection(feat_set)\n",
    "\n",
    "            # Append to doc_features_dict\n",
    "            doc_features_dict[index] = list(interset_words)\n",
    "\n",
    "        return doc_features_dict\n",
    "\n",
    "    def get_bow_dummies(self):\n",
    "        \"\"\"\n",
    "        Replace 0's with 1 in positions of a bow dataframe\n",
    "        to indicate that feature words are present in docs\n",
    "        \"\"\"\n",
    "\n",
    "        # Get an np matrix of zeros based on defined dim\n",
    "        zero_matrix = np.zeros(self.dim, np.int)\n",
    "\n",
    "        # Create a dataframe containing feature columns and 0's\n",
    "        self.zero_df = pd.DataFrame(zero_matrix, columns=self.features)\n",
    "\n",
    "        # Get a dictionary of index and features per doc\n",
    "        doc_features_dict = self.index_feats_dict()\n",
    "        doc_ids = doc_features_dict.keys()\n",
    "        doc_feats = doc_features_dict.values()\n",
    "\n",
    "        # For each row in zero_df, indicate 1 for every\n",
    "        # feature word present in a doc of a dataframe\n",
    "        for index, feats in zip(doc_ids, doc_feats):\n",
    "            self.zero_df.ix[index, feats] = 1\n",
    "\n",
    "        return self.zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetBowDummies_Array(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs: (1) Series with a text vector (2) Bag of Words for features\n",
    "    Output: Dataframe with dummy variables indicating whether a feature word is present in a row.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    train = pd.Series(['I dont know','polish dont','fire','healthcare know','healthcare'])\n",
    "    test  = pd.Series(['I dont know','healthcare know'])\n",
    "    feats = ['dont','know','healthcare']\n",
    "\n",
    "    train_bow_dummies = GetBowDummies(train, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies = GetBowDummies(test, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies\n",
    "     >> dont  know  healthcare\n",
    "        0     0     0           0\n",
    "        1     0     0           0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    def __init__(self, series, features):\n",
    "        \"\"\"\n",
    "        :param series: A column containing raw text\n",
    "        :param features: A list of feature words\n",
    "        \"\"\"\n",
    "        features.sort()\n",
    "        \n",
    "        self.series = series\n",
    "        self.index  = self.series.index\n",
    "        self.features = np.asarray(features)\n",
    "\n",
    "        # Define dimension\n",
    "        self.nrows = series.shape[0]\n",
    "        self.ncols = len(features)\n",
    "        self.dim   = (self.nrows, self.ncols)\n",
    "\n",
    "    def index_feats_dict(self):\n",
    "        \"\"\"\n",
    "        For every document row, features present in doc\n",
    "        identified.\n",
    "        \"\"\"\n",
    "        doc_features_list = []\n",
    "\n",
    "        for i, doc in enumerate(self.series):\n",
    "            # Sets for a doc and feature words\n",
    "            \n",
    "            doc_set = set(doc.split())\n",
    "            feat_set = set(self.features)\n",
    "\n",
    "            # Shared words between the two sets\n",
    "            interset_words = np.asarray(list(doc_set.intersection(feat_set)))\n",
    "            \n",
    "            if len(interset_words) != 0: \n",
    "                ndx = np.searchsorted(self.features, interset_words)\n",
    "                doc_features_list.append(np.asarray([1 if i in ndx else 0 for i in range(self.ncols)]))\n",
    "            else:\n",
    "                doc_features_list.append(np.asarray([0 for i in range(self.ncols)])) \n",
    "\n",
    "        return np.matrix(doc_features_list)\n",
    "\n",
    "        # feat1 feat2 feat3\n",
    "        # Find element location of feat and generate sparse one row at a time\n",
    "        # append it to another array \n",
    "        \n",
    "        #return # self.zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetBowDummies_Array2(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs: (1) Series with a text vector (2) Bag of Words for features\n",
    "    Output: Dataframe with dummy variables indicating whether a feature word is present in a row.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    train = pd.Series(['I dont know','polish dont','fire','healthcare know','healthcare'])\n",
    "    test  = pd.Series(['I dont know','healthcare know'])\n",
    "    feats = ['dont','know','healthcare']\n",
    "\n",
    "    train_bow_dummies = GetBowDummies(train, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies = GetBowDummies(test, feats).get_bow_dummies()\n",
    "\n",
    "    test_bow_dummies\n",
    "     >> dont  know  healthcare\n",
    "        0     0     0           0\n",
    "        1     0     0           0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    def __init__(self, series, features):\n",
    "        \"\"\"\n",
    "        :param series: A column containing raw text\n",
    "        :param features: A list of feature words\n",
    "        \"\"\"\n",
    "        features.sort()\n",
    "        \n",
    "        self.series = series\n",
    "        self.index  = self.series.index\n",
    "        self.features = np.asarray(features)\n",
    "\n",
    "        # Define dimension\n",
    "        self.nrows = series.shape[0]\n",
    "        self.ncols = len(features)\n",
    "        self.dim   = (self.nrows, self.ncols)\n",
    "\n",
    "    def index_feats_dict(self):\n",
    "        \"\"\"\n",
    "        For every document row, features present in doc\n",
    "        identified.\n",
    "        \"\"\"\n",
    "        # doc_features_list = []\n",
    "        zero_matrix = np.zeros(self.dim, np.int)\n",
    "\n",
    "        for i, doc in enumerate(self.series):\n",
    "            # Sets for a doc and feature words\n",
    "            \n",
    "            doc_set = set(doc.split())\n",
    "            feat_set = set(self.features)\n",
    "\n",
    "            # Shared words between the two sets\n",
    "            interset_words = np.asarray(list(doc_set.intersection(feat_set)))\n",
    "            \n",
    "            if len(interset_words) != 0: \n",
    "                ndx = np.searchsorted(self.features, interset_words)\n",
    "                zero_matrix[i,ndx] = 1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        return zero_matrix\n",
    "\n",
    "        # feat1 feat2 feat3\n",
    "        # Find element location of feat and generate sparse one row at a time\n",
    "        # append it to another array \n",
    "        \n",
    "        #return # self.zero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_to_test = [100]#, 100, 500] #, 1000, 5000]\n",
    "trainF1 = []\n",
    "testF1  = []\n",
    "k_model_dict = {}\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encode = le.fit(trainy['category'])\n",
    "train_true_y = le.transform(trainy['category'])\n",
    "test_true_y = le.transform(testy['category'])\n",
    "\n",
    "for k in k_to_test:\n",
    "    \n",
    "    top_k_features_per_topic = {}\n",
    "    for topic in topics:\n",
    "        top_k_features = tfidf_at_k(mod, topic_vector[topic], word_key, k)\n",
    "        top_k_features_per_topic[topic] = top_k_features\n",
    "\n",
    "    # Create Bow dummies\n",
    "    feats = list(chain.from_iterable(top_k_features_per_topic.values()))\n",
    "    #train_bow = GetBowDummies_Array(trainX['combined'], feats).index_feats_dict()\n",
    "    #test_bow = GetBowDummies(testX['combined'], feats).get_bow_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 29.993335962295532 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_1 = GetBowDummies(trainX['combined'], feats).get_bow_dummies()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 58.2199809551239 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_2 = GetBowDummies_Array(trainX['combined'], feats).index_feats_dict()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17.118018865585327 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "_3 = GetBowDummies_Array2(trainX['combined'], feats).index_feats_dict()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88096212692135933"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X=_1, y=trainy['category'])\n",
    "train_pred_y = mnb.predict(_1)\n",
    "train_pred_y = le.transform(train_pred_y)\n",
    "f1_score(train_pred_y, train_true_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88097379044320878"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X=_2, y=trainy['category'])\n",
    "train_pred_y = mnb.predict(_2)\n",
    "train_pred_y = le.transform(train_pred_y)\n",
    "f1_score(train_pred_y, train_true_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88097379044320878"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X=_3, y=trainy['category'])\n",
    "train_pred_y = mnb.predict(_3)\n",
    "train_pred_y = le.transform(train_pred_y)\n",
    "f1_score(train_pred_y, train_true_y, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delte above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "#from operator import itemgetter\n",
    "#from itemgetter import chain\n",
    "\n",
    "def topic_index(series, topic):\n",
    "    return series.ix[series == topic].index\n",
    "\n",
    "def text_joiner(x):\n",
    "    return ' '.join(x)\n",
    "\n",
    "def corpusCreator(df, labelSeries):\n",
    "    \n",
    "    text = {}\n",
    "    for topic in labelSeries.unique():\n",
    "        index = topic_index(labelSeries, topic)\n",
    "        topicText = []\n",
    "        for sent in df[index]:\n",
    "            topicText += sent.split()\n",
    "        text[topic] = topicText \n",
    "    \n",
    "    return text\n",
    "    \n",
    "def tfidf(bags_of_words):\n",
    "    \n",
    "    \"\"\" Fetches the top words in k based on TF-IDF scores.\n",
    "        Returns a list of words with top K.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch id for each word\n",
    "    idDict = corpora.Dictionary(bags_of_words)\n",
    "    \n",
    "    # Get the reverse key-vaule mapping\n",
    "    inv_Dict = {v:k for v, k in idDict.items()}\n",
    "    \n",
    "    # Transform tCorpus into vector form\n",
    "    vCorpus = [idDict.doc2bow(tokens) for tokens in bags_of_words]\n",
    "\n",
    "    # Fit TFIDF\n",
    "    tfidf = models.TfidfModel(vCorpus)\n",
    "    \n",
    "    return tfidf, inv_Dict, vCorpus\n",
    "\n",
    "def tfidf_at_k(tfidf, doc_vector, word_key, k):\n",
    "    \n",
    "    top_k_id_scores = sorted(tfidf[doc_vector], key=itemgetter(1), reverse=True)[:k]\n",
    "    \n",
    "    return [word_key[key] for key, word in top_k_id_scores] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 completed\n",
      "100 completed\n",
      "500 completed\n",
      "1000 completed\n",
      "3000 completed\n",
      "5000 completed\n",
      "7500 completed\n",
      "10000 completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "\n",
    "## Perform Feature Selection using top K TF-IDF per Class\n",
    "\n",
    "# Choose kth threshold\n",
    "\n",
    "class_dictionary = corpusCreator(trainX['combined'], trainy['category'])\n",
    "topics = class_dictionary.keys()\n",
    "mod, word_key, vCorpus = tfidf(list(class_dictionary.values()))\n",
    "topic_vector = {topic: document for topic, document in zip(topics, vCorpus)}\n",
    "\n",
    "k_to_test = [50, 100, 500, 1000, 3000, 5000, 7500, 10000]\n",
    "model_result_dict = {}\n",
    "k_model_dict = {}\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encode = le.fit(trainy['category'])\n",
    "train_true_y = le.transform(trainy['category'])\n",
    "test_true_y = le.transform(testy['category'])\n",
    "\n",
    "for k in k_to_test:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    top_k_features_per_topic = {}\n",
    "    for topic in topics:\n",
    "        top_k_features = tfidf_at_k(mod, topic_vector[topic], word_key, k)\n",
    "        top_k_features_per_topic[topic] = top_k_features\n",
    "\n",
    "    # Create Bow dummies\n",
    "    feats = list(chain.from_iterable(top_k_features_per_topic.values()))\n",
    "    train_bow = GetBowDummies_Array2(trainX['combined'], feats).index_feats_dict()\n",
    "    test_bow = GetBowDummies_Array2(testX['combined'], feats).index_feats_dict()\n",
    "    \n",
    "    # Fit Model \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X=train_bow, y=trainy['category'])\n",
    "    k_model_dict[k] = mnb\n",
    "    joblib.dump(mnb, str(k)+'_'+'mnb_model.pkl') \n",
    "    \n",
    "    # Make train and test predictions\n",
    "    train_pred_y = mnb.predict(train_bow)\n",
    "    test_pred_y = mnb.predict(test_bow)\n",
    "    \n",
    "    # Measure time\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # Apply encoder \n",
    "    train_pred_y = le.transform(train_pred_y)\n",
    "    test_pred_y = le.transform(test_pred_y)\n",
    "    \n",
    "    # Evaluate F1\n",
    "    trainF1 = f1_score(train_pred_y, train_true_y, average='macro') \n",
    "    testF1 = f1_score(test_pred_y, test_true_y, average='macro')\n",
    "    \n",
    "    # Store the result in dictionary \n",
    "    model_result = {'duration': duration, 'trainF1': trainF1, 'testF1': testF1, \\\n",
    "                    'train_pred_y': train_pred_y, 'test_pred_y': test_pred_y}\n",
    "\n",
    "    model_result_dict[k] = model_result\n",
    "    \n",
    "    print(k, 'completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Columns for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: {'duration': 12.492578029632568,\n",
       "  'testF1': 0.71763763281824777,\n",
       "  'test_pred_y': array([3, 1, 3, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.83320617933125707,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 100: {'duration': 22.529353141784668,\n",
       "  'testF1': 0.77021222471766493,\n",
       "  'test_pred_y': array([3, 1, 3, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.87302681194389875,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 500: {'duration': 106.49285817146301,\n",
       "  'testF1': 0.86393227552622731,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.93847142014563634,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 1000: {'duration': 867.7104859352112,\n",
       "  'testF1': 0.88319030556919287,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.95267765337301091,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 3000: {'duration': 891.8288180828094,\n",
       "  'testF1': 0.9030717877691804,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.96321019421099818,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 5000: {'duration': 3132.5426778793335,\n",
       "  'testF1': 0.90603860193581676,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.9667483825650991,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 7500: {'duration': 8007.123059988022,\n",
       "  'testF1': 0.90529746624851182,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.96787376360654676,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])},\n",
       " 10000: {'duration': 10695.186378955841,\n",
       "  'testF1': 0.90619000248987602,\n",
       "  'test_pred_y': array([4, 1, 1, ..., 3, 1, 3]),\n",
       "  'trainF1': 0.96779571199053727,\n",
       "  'train_pred_y': array([3, 3, 2, ..., 3, 3, 5])}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'pred':test_pred_y,'true':test_true_y})\n",
    "result['pred'] = result['pred'].map(lambda x: le.inverse_transform(x)) \n",
    "result['true'] = result['true'].map(lambda x: le.inverse_transform(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>true</th>\n",
       "      <th>biology</th>\n",
       "      <th>cooking</th>\n",
       "      <th>crypto</th>\n",
       "      <th>diy</th>\n",
       "      <th>robotics</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>177</td>\n",
       "      <td>192</td>\n",
       "      <td>130</td>\n",
       "      <td>346</td>\n",
       "      <td>34</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooking</th>\n",
       "      <td>845</td>\n",
       "      <td>1015</td>\n",
       "      <td>713</td>\n",
       "      <td>1708</td>\n",
       "      <td>163</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crypto</th>\n",
       "      <td>379</td>\n",
       "      <td>449</td>\n",
       "      <td>309</td>\n",
       "      <td>753</td>\n",
       "      <td>90</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diy</th>\n",
       "      <td>877</td>\n",
       "      <td>1026</td>\n",
       "      <td>632</td>\n",
       "      <td>1616</td>\n",
       "      <td>172</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robotics</th>\n",
       "      <td>319</td>\n",
       "      <td>410</td>\n",
       "      <td>261</td>\n",
       "      <td>673</td>\n",
       "      <td>76</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>698</td>\n",
       "      <td>838</td>\n",
       "      <td>541</td>\n",
       "      <td>1316</td>\n",
       "      <td>138</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "true      biology  cooking  crypto   diy  robotics  travel\n",
       "pred                                                      \n",
       "biology       177      192     130   346        34     252\n",
       "cooking       845     1015     713  1708       163    1305\n",
       "crypto        379      449     309   753        90     552\n",
       "diy           877     1026     632  1616       172    1236\n",
       "robotics      319      410     261   673        76     496\n",
       "travel        698      838     541  1316       138    1013"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a crosstab of true/false prediction counts per category\n",
    "pd.crosstab(result['pred'], result['true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIY is overpowering prediction, which can be partially explained given that from the train features contain mostly diy topics. Another reason could be that words in a lot of words in DIY are commonly found in other topics so it might be difficult for the classification to clearly distinguish whether a topic is DIY or any other topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    19506\n",
       "5    14425\n",
       "1    11474\n",
       "0     9901\n",
       "2     7846\n",
       "4     2098\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_true_y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Are there a lot of overlapping features indicated between DIY vs Biology in train matrix such that it's\n",
    "# difificult for the model can't distinguish between the two vs if it was robotics vs crypto? \n",
    "\n",
    "# K-Features \n",
    "# Features in Train\n",
    "# Features in Test\n",
    "# Model Accuracy is poor given that the data isn't Gaussian?\n",
    "\n",
    "# Distribution of mutual information???? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Rare occurrences are what's disrupting accurate prediction. For instance, the term polar bear is a rare term that would result in low TF-IDF score in biology, so when the k-th TIFDF were chosen, the term was weeded out from the features for classifying biology. Some combined contents contain feature words found in other topic, but not in the ones that are actually from the topic itself. \n",
    "\n",
    "One possible solution is to expand the feature set costing more computation time or re-design feature selection and engineering or even possibly dimensionality reduction.\n",
    "\n",
    "Other feature suggestions:\n",
    "\n",
    "- Number of paragraphs\n",
    "- Capitalized acronyms\n",
    "- Dimensionality reduction"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
